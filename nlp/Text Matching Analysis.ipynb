{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "24ffe80c-6f7d-4d70-8930-a2119d4d1bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f792c94c-af8d-4f39-af2c-ef366da505a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## clean the text and convert to lower string and replace all of punctuation\n",
    "def clean_text(text):\n",
    "    text = text.strip().lower()\n",
    "    punctuation = string.punctuation\n",
    "\n",
    "    for p in punctuation:\n",
    "        text = text.replace(p, \" \")\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "## caculate the consine similarity score based on TfidfVectorizer\n",
    "def string_similarity(string1, string2, method=\"TF-IDF\"):\n",
    "    if string1 is None or string2 is None:\n",
    "        return -1\n",
    "\n",
    "    string1 = clean_text(string1)\n",
    "    string2 = clean_text(string2)\n",
    "\n",
    "    if len(string1) == 0 or len(string2) == 0:\n",
    "        return -1\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(analyzer='char')\n",
    "    if method == \"Count\":\n",
    "        vectorizer = CountVectorizer(analyzer='char')\n",
    "    vectors = vectorizer.fit_transform([string1, string2])\n",
    "    similarity = cosine_similarity(vectors)\n",
    "    return similarity[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1b51df16-dc55-4f46-b745-006bad1ebf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string1: Lucy Anderson, string2: Lucia Ivenson\n",
      "string1 and string2 matching score: 0.6059671415042287\n"
     ]
    }
   ],
   "source": [
    "string1 = \"Lucy Anderson\"\n",
    "string2 = \"Lucia Ivenson\"\n",
    "\n",
    "print(\"string1: {}, string2: {}\".format(string1, string2))\n",
    "print(\"string1 and string2 matching score: {}\".format(string_similarity(string1, string2,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4193a207-28d9-4ca2-b290-c3a56aff2bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string1: Lucy Anderson, string2:   \n",
      "string1 and string2 matching score: -1\n"
     ]
    }
   ],
   "source": [
    "string1 = \"Lucy Anderson\"\n",
    "string2 = \"  \"\n",
    "\n",
    "print(\"string1: {}, string2: {}\".format(string1, string2))\n",
    "print(\"string1 and string2 matching score: {}\".format(string_similarity(string1, string2,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5a094f3a-b025-4b20-abe5-3fc636a86b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0  # To avoid division by zero\n",
    "\n",
    "def string_jaccard_similarity(string1, string2):\n",
    "    if string1 is None or string2 is None:\n",
    "        return -1\n",
    "\n",
    "    string1 = clean_text(string1)\n",
    "    string2 = clean_text(string2)\n",
    "\n",
    "    if len(string1) == 0 or len(string2) == 0:\n",
    "        return -1\n",
    "\n",
    "    string1_set = set(string1)\n",
    "    string2_set = set(string2)\n",
    "    return jaccard_similarity(string1_set, string2_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "afe9c57a-c513-4ff6-bd96-f0818ceec1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity: 1.0\n"
     ]
    }
   ],
   "source": [
    "string1 = \"Tom Jeff\"\n",
    "string2 = \"Jeff Tom\"\n",
    "\n",
    "similarity_score = string_jaccard_similarity(string1, string2)\n",
    "print(\"Jaccard Similarity:\", similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "47df3bf4-e7c5-472a-bf78-63d025d7820c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaro Similarity: 0.3333333333333333\n",
      "Jaro-Winkler Similarity: 0.3333333333333333\n",
      "Jaccard Similarity: 1.0\n"
     ]
    }
   ],
   "source": [
    "import textdistance\n",
    "\n",
    "string1 = \"Tom Jeff\"\n",
    "string2 = \"Jeff Tom\"\n",
    "\n",
    "jaro_similarity_score = textdistance.jaro(string1, string2)\n",
    "jaro_winkler_similarity_score = textdistance.jaro_winkler(string1, string2)\n",
    "jaccard_similarity_score = textdistance.jaccard(string1, string2)\n",
    "print(\"Jaro Similarity:\", jaro_similarity_score)\n",
    "print(\"Jaro-Winkler Similarity:\", jaro_winkler_similarity_score)\n",
    "print(\"Jaccard Similarity:\", jaccard_similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a269c602-952a-4cc6-95af-f2993dbc29a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c857c4d1-ef9f-4533-9142-ffe1259daf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_char_tensor(text):\n",
    "    # Convert text to lowercase and split into characters\n",
    "    text = clean_text(text)\n",
    "    chars = list(text)\n",
    "    # Convert characters to ASCII values\n",
    "    char_values = [ord(char) for char in chars]\n",
    "    # Convert ASCII values into a tensor\n",
    "    return torch.tensor(char_values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6db88b3d-7e6a-43f6-a28f-22a621d7b9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_consine_similarity(string1, string2):\n",
    "    \n",
    "    if string1 is None or string2 is None:\n",
    "        return -1\n",
    "\n",
    "    string1 = clean_text(string1)\n",
    "    string2 = clean_text(string2)\n",
    "\n",
    "    if len(string1) == 0 or len(string2) == 0:\n",
    "        return -1\n",
    "    # Convert text strings to tensors\n",
    "    tensor1 = text_to_char_tensor(string1)\n",
    "    tensor2 = text_to_char_tensor(string2)\n",
    "    similarity = F.cosine_similarity(tensor1, tensor2, dim=0)\n",
    "    return similarity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7321408f-0499-40a3-8a74-794841b9e056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String Consince Similarity: 0.9321610927581787\n"
     ]
    }
   ],
   "source": [
    "string1 = \"Tom Jeff\"\n",
    "string2 = \"Jeff Tom\"\n",
    "\n",
    "print(\"String Consince Similarity:\", string_consine_similarity(string1, string2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "704b49eb-eb03-4731-878e-a383330839f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String Consince Similarity: -1\n"
     ]
    }
   ],
   "source": [
    "string1 = \"Tom Jeff\"\n",
    "string2 = \"\"\n",
    "\n",
    "print(\"String Consince Similarity:\", string_consine_similarity(string1, string2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4c0bc88f-1ae5-4d51-b64f-63e14de9292b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String Consince Similarity: 0.9681525230407715\n"
     ]
    }
   ],
   "source": [
    "string1 = \"Lucy Anderson\"\n",
    "string2 = \"Lucia Ivenson\"\n",
    "\n",
    "print(\"String Consince Similarity:\", string_consine_similarity(string1, string2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a2751a15-1357-46fd-bf64-cdc912886fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000007"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string1 = \"Tom Jeff\"\n",
    "string2 = \"Jeff Tom\"\n",
    "\n",
    "string_similarity(string1, string2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f1dcd6-c397-4002-a4c9-a79c18054653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ce2206-c513-4b53-a9c0-11b4f1a28040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
